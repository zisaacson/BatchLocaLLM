================================================================================
SCALABILITY BENCHMARK
================================================================================

Initializing Ollama backend...
✅ Ollama server healthy
✅ Model loaded: gemma3:12b

================================================================================
BENCHMARK: 100 requests with 4 workers
================================================================================
Creating 100 test requests...
✅ Created 100 requests
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "\n============================================================\nPARALLEL BATCH PROCESSING\n============================================================\nTotal requests: 100\nWorkers: 4\nRequests per worker: ~25\n============================================================", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "Starting 4 workers...", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 starting: 25 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 starting: 25 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 starting: 25 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:46", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 starting: 25 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 10/25 (40.0%) | Rate: 3.72 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 10/25 (40.0%) | Rate: 3.62 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 10/25 (40.0%) | Rate: 3.52 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 10/25 (40.0%) | Rate: 3.44 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 20/25 (80.0%) | Rate: 3.50 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 20/25 (80.0%) | Rate: 3.46 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 20/25 (80.0%) | Rate: 3.41 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 20/25 (80.0%) | Rate: 3.37 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 completed: 25/25 successful | Time: 7.2s | Rate: 3.47 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 completed: 25/25 successful | Time: 7.3s | Rate: 3.43 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 completed: 25/25 successful | Time: 7.4s | Rate: 3.40 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 completed: 25/25 successful | Time: 7.4s | Rate: 3.36 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "\n============================================================\nBATCH COMPLETE\n============================================================\nTotal requests: 100\nSuccessful: 100 (100.0%)\nFailed: 0 (0.0%)\nTotal time: 0.1 minutes\nOverall rate: 13.46 req/s\nSpeedup: 67.3x vs sequential\n============================================================", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "\nPer-Worker Statistics:", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 0: 25/25 | 3.43 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 1: 25/25 | 3.36 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 2: 25/25 | 3.40 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 3: 25/25 | 3.47 req/s | 0 retries", "service": "vllm-batch-server"}

================================================================================
RESULTS FOR 100 REQUESTS:
================================================================================
Success:  100/100 (100.0%)
Failed:   0
Time:     7.4s (0.12 minutes)
Rate:     13.46 req/s
Speedup:  67.3x vs baseline

================================================================================
BENCHMARK: 500 requests with 4 workers
================================================================================
Creating 500 test requests...
✅ Created 500 requests
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "\n============================================================\nPARALLEL BATCH PROCESSING\n============================================================\nTotal requests: 500\nWorkers: 4\nRequests per worker: ~125\n============================================================", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Starting 4 workers...", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 starting: 125 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 starting: 125 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 starting: 125 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:54", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 starting: 125 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:57", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 10/125 (8.0%) | Rate: 3.37 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:57", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 10/125 (8.0%) | Rate: 3.28 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:57", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 10/125 (8.0%) | Rate: 3.21 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:52:57", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 10/125 (8.0%) | Rate: 3.13 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:00", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 20/125 (16.0%) | Rate: 3.26 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:00", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 20/125 (16.0%) | Rate: 3.22 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:00", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 20/125 (16.0%) | Rate: 3.18 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:00", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 20/125 (16.0%) | Rate: 3.14 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:03", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 30/125 (24.0%) | Rate: 3.22 req/s | Success: 24.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:03", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 30/125 (24.0%) | Rate: 3.20 req/s | Success: 24.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:03", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 30/125 (24.0%) | Rate: 3.17 req/s | Success: 24.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:03", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 30/125 (24.0%) | Rate: 3.14 req/s | Success: 24.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:06", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 40/125 (32.0%) | Rate: 3.21 req/s | Success: 32.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:06", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 40/125 (32.0%) | Rate: 3.18 req/s | Success: 32.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:06", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 40/125 (32.0%) | Rate: 3.17 req/s | Success: 32.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:06", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 40/125 (32.0%) | Rate: 3.15 req/s | Success: 32.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:09", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 50/125 (40.0%) | Rate: 3.20 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:10", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 50/125 (40.0%) | Rate: 3.18 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:10", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 50/125 (40.0%) | Rate: 3.16 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:10", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 50/125 (40.0%) | Rate: 3.15 req/s | Success: 40.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:13", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 60/125 (48.0%) | Rate: 3.16 req/s | Success: 48.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:13", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 60/125 (48.0%) | Rate: 3.15 req/s | Success: 48.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:13", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 60/125 (48.0%) | Rate: 3.13 req/s | Success: 48.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:13", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 60/125 (48.0%) | Rate: 3.12 req/s | Success: 48.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:16", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 70/125 (56.0%) | Rate: 3.14 req/s | Success: 56.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:16", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 70/125 (56.0%) | Rate: 3.13 req/s | Success: 56.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:16", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 70/125 (56.0%) | Rate: 3.11 req/s | Success: 56.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:16", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 70/125 (56.0%) | Rate: 3.10 req/s | Success: 56.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:19", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 80/125 (64.0%) | Rate: 3.12 req/s | Success: 64.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:20", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 80/125 (64.0%) | Rate: 3.11 req/s | Success: 64.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:20", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 80/125 (64.0%) | Rate: 3.10 req/s | Success: 64.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:20", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 80/125 (64.0%) | Rate: 3.09 req/s | Success: 64.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:23", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 90/125 (72.0%) | Rate: 3.10 req/s | Success: 72.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:23", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 90/125 (72.0%) | Rate: 3.09 req/s | Success: 72.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:23", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 90/125 (72.0%) | Rate: 3.09 req/s | Success: 72.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:23", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 90/125 (72.0%) | Rate: 3.08 req/s | Success: 72.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:26", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 100/125 (80.0%) | Rate: 3.09 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:26", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 100/125 (80.0%) | Rate: 3.08 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:26", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 100/125 (80.0%) | Rate: 3.08 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:26", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 100/125 (80.0%) | Rate: 3.07 req/s | Success: 80.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:29", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 110/125 (88.0%) | Rate: 3.08 req/s | Success: 88.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:30", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 110/125 (88.0%) | Rate: 3.08 req/s | Success: 88.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:30", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 110/125 (88.0%) | Rate: 3.07 req/s | Success: 88.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:30", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 110/125 (88.0%) | Rate: 3.06 req/s | Success: 88.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:33", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 120/125 (96.0%) | Rate: 3.08 req/s | Success: 96.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:33", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 120/125 (96.0%) | Rate: 3.07 req/s | Success: 96.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:33", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 120/125 (96.0%) | Rate: 3.06 req/s | Success: 96.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:33", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 120/125 (96.0%) | Rate: 3.06 req/s | Success: 96.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:34", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 completed: 125/125 successful | Time: 40.7s | Rate: 3.07 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 completed: 125/125 successful | Time: 40.8s | Rate: 3.07 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 completed: 125/125 successful | Time: 40.9s | Rate: 3.06 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 completed: 125/125 successful | Time: 40.9s | Rate: 3.05 req/s", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "\n============================================================\nBATCH COMPLETE\n============================================================\nTotal requests: 500\nSuccessful: 500 (100.0%)\nFailed: 0 (0.0%)\nTotal time: 0.7 minutes\nOverall rate: 12.21 req/s\nSpeedup: 61.1x vs sequential\n============================================================", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "\nPer-Worker Statistics:", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 0: 125/125 | 3.06 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 1: 125/125 | 3.07 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 2: 125/125 | 3.07 req/s | 0 retries", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "  Worker 3: 125/125 | 3.05 req/s | 0 retries", "service": "vllm-batch-server"}

================================================================================
RESULTS FOR 500 REQUESTS:
================================================================================
Success:  500/500 (100.0%)
Failed:   0
Time:     40.9s (0.68 minutes)
Rate:     12.21 req/s
Speedup:  61.1x vs baseline

================================================================================
BENCHMARK: 1000 requests with 4 workers
================================================================================
Creating 1000 test requests...
✅ Created 1000 requests
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "\n============================================================\nPARALLEL BATCH PROCESSING\n============================================================\nTotal requests: 1,000\nWorkers: 4\nRequests per worker: ~250\n============================================================", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Starting 4 workers...", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 starting: 250 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 starting: 250 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 starting: 250 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:35", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 starting: 250 requests", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:38", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 10/250 (4.0%) | Rate: 3.10 req/s | Success: 4.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:38", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 10/250 (4.0%) | Rate: 3.00 req/s | Success: 4.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:38", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 10/250 (4.0%) | Rate: 2.92 req/s | Success: 4.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:38", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 10/250 (4.0%) | Rate: 2.86 req/s | Success: 4.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:41", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 20/250 (8.0%) | Rate: 2.97 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:42", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 20/250 (8.0%) | Rate: 2.93 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:42", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 20/250 (8.0%) | Rate: 2.89 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:42", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 20/250 (8.0%) | Rate: 2.86 req/s | Success: 8.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:45", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 30/250 (12.0%) | Rate: 2.93 req/s | Success: 12.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:45", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 30/250 (12.0%) | Rate: 2.91 req/s | Success: 12.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:45", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 30/250 (12.0%) | Rate: 2.88 req/s | Success: 12.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:45", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 30/250 (12.0%) | Rate: 2.86 req/s | Success: 12.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:48", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 40/250 (16.0%) | Rate: 2.91 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 40/250 (16.0%) | Rate: 2.89 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 40/250 (16.0%) | Rate: 2.87 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:49", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 40/250 (16.0%) | Rate: 2.86 req/s | Success: 16.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 1 progress: 50/250 (20.0%) | Rate: 2.90 req/s | Success: 20.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 2 progress: 50/250 (20.0%) | Rate: 2.89 req/s | Success: 20.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 3 progress: 50/250 (20.0%) | Rate: 2.87 req/s | Success: 20.0%", "service": "vllm-batch-server"}
{"timestamp": "2025-10-27T11:53:52", "level": "INFO", "logger": "vllm_batch_server", "message": "Worker 0 progress: 50/250 (20.0%) | Rate: 2.86 req/s | Success: 20.0%", "service": "vllm-batch-server"}
