{
  "dashboard": {
    "title": "vLLM Batch Server - GPU & Performance",
    "tags": ["vllm", "gpu", "batch-processing"],
    "timezone": "browser",
    "editable": true,
    "panels": [
      {
        "id": 100,
        "title": "ðŸŽ® GPU Temperature",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "nvidia_gpu_temperature_celsius",
            "legendFormat": "GPU {{uuid}}",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 100,
          "thresholds": [
            {"value": 0, "color": "green"},
            {"value": 70, "color": "yellow"},
            {"value": 85, "color": "red"}
          ]
        }
      },
      {
        "id": 101,
        "title": "ðŸ’¾ GPU Memory Usage",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0},
        "targets": [
          {
            "expr": "nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes * 100",
            "legendFormat": "GPU {{uuid}}",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 100,
          "unit": "percent"
        }
      },
      {
        "id": 102,
        "title": "âš¡ GPU Power Usage",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "nvidia_gpu_power_usage_milliwatts / 1000",
            "legendFormat": "GPU {{uuid}}",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 350,
          "unit": "watt"
        }
      },
      {
        "id": 103,
        "title": "ðŸ”¥ GPU Utilization",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 18, "y": 0},
        "targets": [
          {
            "expr": "nvidia_gpu_duty_cycle",
            "legendFormat": "GPU {{uuid}}",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 100,
          "unit": "percent"
        }
      },
      {
        "id": 1,
        "title": "GPU Utilization",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "vllm:gpu_cache_usage_perc",
            "legendFormat": "GPU Cache Usage %",
            "refId": "A"
          }
        ]
      },
      {
        "id": 2,
        "title": "Requests Per Second",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "rate(vllm:request_success_total[1m])",
            "legendFormat": "Successful Requests/s",
            "refId": "A"
          },
          {
            "expr": "rate(vllm:request_failure_total[1m])",
            "legendFormat": "Failed Requests/s",
            "refId": "B"
          }
        ]
      },
      {
        "id": 3,
        "title": "Request Latency (P50, P95, P99)",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(vllm:request_duration_seconds_bucket[5m]))",
            "legendFormat": "P50",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.95, rate(vllm:request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95",
            "refId": "B"
          },
          {
            "expr": "histogram_quantile(0.99, rate(vllm:request_duration_seconds_bucket[5m]))",
            "legendFormat": "P99",
            "refId": "C"
          }
        ]
      },
      {
        "id": 4,
        "title": "Tokens Generated Per Second",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "targets": [
          {
            "expr": "rate(vllm:generation_tokens_total[1m])",
            "legendFormat": "Tokens/s",
            "refId": "A"
          }
        ]
      },
      {
        "id": 5,
        "title": "Active Requests",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 16},
        "targets": [
          {
            "expr": "vllm:num_requests_running",
            "refId": "A"
          }
        ]
      },
      {
        "id": 6,
        "title": "Queued Requests",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 16},
        "targets": [
          {
            "expr": "vllm:num_requests_waiting",
            "refId": "A"
          }
        ]
      },
      {
        "id": 7,
        "title": "KV Cache Usage",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 12, "y": 16},
        "targets": [
          {
            "expr": "vllm:gpu_cache_usage_perc",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 100
        }
      },
      {
        "id": 8,
        "title": "Prefix Cache Hit Rate",
        "type": "gauge",
        "gridPos": {"h": 4, "w": 6, "x": 18, "y": 16},
        "targets": [
          {
            "expr": "rate(vllm:prefix_cache_hit_total[5m]) / (rate(vllm:prefix_cache_hit_total[5m]) + rate(vllm:prefix_cache_miss_total[5m])) * 100",
            "refId": "A"
          }
        ],
        "options": {
          "minValue": 0,
          "maxValue": 100
        }
      },
      {
        "id": 9,
        "title": "Batch Size Distribution",
        "type": "heatmap",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 20},
        "targets": [
          {
            "expr": "vllm:batch_size_bucket",
            "format": "heatmap",
            "refId": "A"
          }
        ]
      }
    ],
    "refresh": "5s",
    "time": {
      "from": "now-15m",
      "to": "now"
    }
  }
}

