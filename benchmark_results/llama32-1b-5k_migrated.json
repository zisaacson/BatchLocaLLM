{
  "test_name": "llama32-1b-5k",
  "model": "meta-llama/Llama-3.2-1B-Instruct",
  "mode": "offline_batch",
  "timestamp": "2025-10-28T17:47:15.844887Z",
  "model_load_time_seconds": 210.2,
  "inference_time_seconds": 108.35,
  "total_time_seconds": 318.55,
  "num_requests": 5000,
  "successful_requests": 5000,
  "failed_requests": 0,
  "success_rate_pct": 100.0,
  "prompt_tokens": 1540000,
  "completion_tokens": 606875,
  "total_tokens": 2146875,
  "avg_prompt_tokens": 308.0,
  "avg_completion_tokens": 121.375,
  "throughput_req_per_sec": 46.15,
  "throughput_tokens_per_sec": 19813,
  "latency_p50_ms": 0,
  "latency_p95_ms": 0,
  "latency_p99_ms": 0,
  "latency_min_ms": 0,
  "latency_max_ms": 0,
  "config": {},
  "notes": "Migrated from benchmarks/metadata/llama32-1b-5k-2025-10-28.json"
}