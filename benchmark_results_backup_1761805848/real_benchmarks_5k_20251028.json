[
  {
    "model": "google/gemma-3-4b-it",
    "mode": "vllm_offline_batch",
    "size": 5000,
    "total_time_seconds": 2209.11,
    "model_load_time_seconds": 26.08,
    "inference_time_seconds": 2183.03,
    "throughput_req_per_sec": 2.29,
    "throughput_tokens_per_sec": 2511,
    "prompt_tokens": 3942154,
    "completion_tokens": 1540218,
    "total_tokens": 5482372,
    "avg_prompt_tokens_per_request": 788.4,
    "avg_completion_tokens_per_request": 308.0,
    "errors": 0,
    "success_rate_pct": 100.0,
    "timestamp": "2025-10-28T08:40:32Z",
    "notes": "REAL DATA - Gemma 3 4B took 36.8 minutes total (36.4 min inference)"
  },
  {
    "model": "meta-llama/Llama-3.2-3B-Instruct",
    "mode": "vllm_offline_batch",
    "size": 5000,
    "total_time_seconds": 781.78,
    "model_load_time_seconds": 6.47,
    "inference_time_seconds": 775.31,
    "throughput_req_per_sec": 6.40,
    "throughput_tokens_per_sec": 6695.78,
    "prompt_tokens": 3577156,
    "completion_tokens": 1657438,
    "total_tokens": 5234594,
    "avg_prompt_tokens_per_request": 715.4,
    "avg_completion_tokens_per_request": 331.5,
    "errors": 0,
    "success_rate_pct": 100.0,
    "timestamp": "2025-10-28T19:00:11Z",
    "notes": "REAL DATA - Llama 3.2 3B took 13 minutes total (12.9 min inference)"
  },
  {
    "model": "meta-llama/Llama-3.2-1B-Instruct",
    "mode": "vllm_offline_batch",
    "size": 5000,
    "total_time_seconds": 318.55,
    "model_load_time_seconds": 210.2,
    "inference_time_seconds": 108.35,
    "throughput_req_per_sec": 46.15,
    "throughput_tokens_per_sec": 19813,
    "prompt_tokens": 1540000,
    "completion_tokens": 606875,
    "total_tokens": 2146875,
    "avg_prompt_tokens_per_request": 308.0,
    "avg_completion_tokens_per_request": 121.4,
    "errors": 0,
    "success_rate_pct": 100.0,
    "timestamp": "2025-10-28T17:47:15Z",
    "notes": "REAL DATA - Llama 3.2 1B took 5.3 minutes total (1.8 min inference) - FASTEST but quality issues"
  }
]

