[Unit]
Description=Aristotle vLLM Batch Inference API
After=network.target

[Service]
Type=simple
User=zack
Group=zack
WorkingDirectory=/home/zack/Documents/augment-projects/Local/vllm-batch-server
Environment="PATH=/home/zack/Documents/augment-projects/Local/vllm-batch-server/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="PYTHONUNBUFFERED=1"
ExecStart=/home/zack/Documents/augment-projects/Local/vllm-batch-server/venv/bin/python -m uvicorn core.batch_app.api_server:app --host 0.0.0.0 --port 4080

# Restart policy
Restart=on-failure
RestartSec=10
StartLimitBurst=5
StartLimitIntervalSec=300

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=aristotle-api

# Resource limits
LimitNOFILE=65536
MemoryMax=4G         # Hard limit - kill if exceeded
MemoryHigh=3G        # Soft limit - throttle if exceeded
CPUQuota=200%        # Max 2 CPU cores

# Security
PrivateTmp=true
NoNewPrivileges=true

[Install]
WantedBy=multi-user.target

