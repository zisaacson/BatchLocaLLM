# Codebase Reorganization Plan

**Goal:** Reorganize from Ollama-focused to vLLM native batch processing with multi-model support.

---

## ğŸ¯ Current State vs Target State

### **Current State (Messy):**
```
vllm-batch-server/
â”œâ”€â”€ src/                    # Ollama-specific code (DEPRECATED)
â”‚   â”œâ”€â”€ ollama_backend.py
â”‚   â”œâ”€â”€ batch_processor.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ batch_app/              # NEW vLLM web app (KEEP)
â”œâ”€â”€ benchmarks/             # Benchmark data (KEEP)
â”œâ”€â”€ tools/                  # Various scripts (REORGANIZE)
â”œâ”€â”€ tests/                  # Old tests (UPDATE)
â””â”€â”€ 50+ markdown files      # Documentation (CONSOLIDATE)
```

### **Target State (Clean):**
```
vllm-batch-server/
â”œâ”€â”€ batch_api/              # Web API for batch processing
â”‚   â”œâ”€â”€ server.py           # FastAPI server
â”‚   â”œâ”€â”€ worker.py           # Background worker
â”‚   â”œâ”€â”€ database.py         # Database models
â”‚   â””â”€â”€ benchmarks.py       # Benchmark integration
â”œâ”€â”€ models/                 # Model configurations
â”‚   â”œâ”€â”€ gemma3_4b.py
â”‚   â”œâ”€â”€ llama32_1b.py
â”‚   â”œâ”€â”€ qwen3_4b.py
â”‚   â””â”€â”€ registry.py         # Model registry
â”œâ”€â”€ benchmarks/             # Benchmark data and tools
â”‚   â”œâ”€â”€ data/               # Benchmark results
â”‚   â”œâ”€â”€ tools/              # Benchmark scripts
â”‚   â””â”€â”€ reports/            # Analysis reports
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_worker.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ README.md           # Main docs
â”‚   â”œâ”€â”€ API.md              # API reference
â”‚   â”œâ”€â”€ BENCHMARKING.md     # Benchmark guide
â”‚   â””â”€â”€ MODELS.md           # Model guide
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â”œâ”€â”€ start_server.sh
â”‚   â”œâ”€â”€ start_worker.sh
â”‚   â””â”€â”€ run_benchmark.sh
â””â”€â”€ examples/               # Example usage
    â”œâ”€â”€ submit_batch.py
    â””â”€â”€ monitor_job.py
```

---

## ğŸ“‹ Migration Steps

### **Step 1: Rename and Reorganize Core**
```bash
# Rename batch_app to batch_api
mv batch_app batch_api

# Update imports in all files
# batch_app.api_server -> batch_api.server
# batch_app.worker -> batch_api.worker
```

### **Step 2: Archive Ollama Code**
```bash
# Move deprecated Ollama code to archive
mkdir -p archive/ollama
mv src/ archive/ollama/
mv README_OLLAMA_BATCH.md archive/ollama/
```

### **Step 3: Create Models Directory**
```bash
mkdir -p models
# Create model configuration files
```

### **Step 4: Consolidate Documentation**
```bash
mkdir -p docs
# Move key docs to docs/
# Archive old docs
```

### **Step 5: Clean Up Root**
```bash
# Keep only essential files in root:
# - README.md (new, comprehensive)
# - pyproject.toml
# - .gitignore
# - LICENSE
```

---

## ğŸ“ New File Structure

### **batch_api/** (Core Application)
```
batch_api/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ server.py               # FastAPI server (renamed from api_server.py)
â”œâ”€â”€ worker.py               # Background worker
â”œâ”€â”€ database.py             # Database models
â”œâ”€â”€ benchmarks.py           # Benchmark integration
â””â”€â”€ config.py               # Configuration management
```

### **models/** (Model Configurations)
```
models/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ registry.py             # Model registry and loader
â”œâ”€â”€ base.py                 # Base model configuration
â”œâ”€â”€ gemma3_4b.py           # Gemma 3 4B config
â”œâ”€â”€ gemma3_12b.py          # Gemma 3 12B config
â”œâ”€â”€ llama32_1b.py          # Llama 3.2 1B config
â”œâ”€â”€ llama32_3b.py          # Llama 3.2 3B config
â”œâ”€â”€ qwen3_4b.py            # Qwen 3 4B config
â”œâ”€â”€ qwen3_7b.py            # Qwen 3 7B config
â””â”€â”€ olmo_1b.py             # OLMo 1B config
```

### **benchmarks/** (Benchmark System)
```
benchmarks/
â”œâ”€â”€ data/                   # Benchmark results
â”‚   â”œâ”€â”€ metadata/           # JSON metadata files
â”‚   â””â”€â”€ raw/                # Raw JSONL results
â”œâ”€â”€ tools/                  # Benchmark scripts
â”‚   â”œâ”€â”€ run_benchmark.py
â”‚   â”œâ”€â”€ analyze_results.py
â”‚   â””â”€â”€ compare_models.py
â””â”€â”€ reports/                # Analysis reports
    â””â”€â”€ BENCHMARKING_JOURNEY.md
```

### **docs/** (Documentation)
```
docs/
â”œâ”€â”€ README.md               # Main documentation
â”œâ”€â”€ API.md                  # API reference
â”œâ”€â”€ BENCHMARKING.md         # Benchmark guide
â”œâ”€â”€ MODELS.md               # Model guide
â”œâ”€â”€ DEPLOYMENT.md           # Deployment guide
â””â”€â”€ ARCHITECTURE.md         # System architecture
```

### **scripts/** (Utility Scripts)
```
scripts/
â”œâ”€â”€ start_server.sh         # Start API server
â”œâ”€â”€ start_worker.sh         # Start worker
â”œâ”€â”€ run_benchmark.sh        # Run benchmark
â””â”€â”€ setup.sh                # Initial setup
```

### **tests/** (Test Suite)
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_api.py             # API tests
â”œâ”€â”€ test_worker.py          # Worker tests
â”œâ”€â”€ test_models.py          # Model tests
â””â”€â”€ test_benchmarks.py      # Benchmark tests
```

---

## ğŸ”§ Implementation Plan

### **Phase 1: Core Reorganization** (30 minutes)
1. âœ… Rename `batch_app` â†’ `batch_api`
2. âœ… Update all imports
3. âœ… Create `models/` directory
4. âœ… Create model configuration files
5. âœ… Update startup scripts

### **Phase 2: Documentation Consolidation** (20 minutes)
1. âœ… Create new comprehensive README.md
2. âœ… Move key docs to `docs/`
3. âœ… Archive old docs to `archive/docs/`
4. âœ… Update all doc links

### **Phase 3: Archive Ollama Code** (10 minutes)
1. âœ… Create `archive/ollama/`
2. âœ… Move `src/` to archive
3. âœ… Move Ollama-specific docs to archive
4. âœ… Update .gitignore

### **Phase 4: Clean Up Root** (10 minutes)
1. âœ… Remove unnecessary files
2. âœ… Keep only essential files
3. âœ… Update pyproject.toml
4. âœ… Update .gitignore

### **Phase 5: Update Tests** (20 minutes)
1. âœ… Update test imports
2. âœ… Add new model tests
3. âœ… Add API tests
4. âœ… Run test suite

---

## ğŸ“ New README.md Structure

```markdown
# vLLM Batch Processing Server

**Production-ready batch inference system for large-scale LLM processing on consumer GPUs.**

## Features
- âœ… Native vLLM batch processing
- âœ… Multi-model support (Gemma, Llama, Qwen, OLMo)
- âœ… Web API for job submission
- âœ… Automatic benchmarking
- âœ… Progress tracking
- âœ… Optimized for RTX 4080 16GB

## Quick Start
[Installation, usage, examples]

## Supported Models
[Model list with benchmarks]

## API Reference
[API documentation]

## Benchmarking
[Benchmark results and guide]

## Architecture
[System architecture]
```

---

## ğŸ¯ Benefits of Reorganization

### **Before:**
- âŒ Mixed Ollama and vLLM code
- âŒ 50+ markdown files in root
- âŒ Unclear project structure
- âŒ Hard to find relevant code
- âŒ Model configs scattered

### **After:**
- âœ… Pure vLLM native batch processing
- âœ… Clean, organized structure
- âœ… Clear separation of concerns
- âœ… Easy to add new models
- âœ… Professional, maintainable codebase

---

## ğŸš€ Next Steps

1. **Execute reorganization** (1-2 hours)
2. **Update GitHub repo** (30 minutes)
3. **Test everything works** (30 minutes)
4. **Update documentation** (30 minutes)
5. **Commit and push** (10 minutes)

**Total Time:** ~3 hours

---

**Ready to execute?** This will transform the codebase into a professional, production-ready system.

